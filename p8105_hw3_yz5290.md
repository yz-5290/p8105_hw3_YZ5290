p8105_hw3_YZ5290
================
2025-10-13

Problem 1

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.1
    ## ✔ ggplot2   4.0.0     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.4     ✔ tidyr     1.3.1
    ## ✔ purrr     1.0.2     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library(patchwork)
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

``` r
library(p8105.datasets)
data("instacart")
```

``` r
instacart
```

    ## # A tibble: 1,384,617 × 15
    ##    order_id product_id add_to_cart_order reordered user_id eval_set order_number
    ##       <int>      <int>             <int>     <int>   <int> <chr>           <int>
    ##  1        1      49302                 1         1  112108 train               4
    ##  2        1      11109                 2         1  112108 train               4
    ##  3        1      10246                 3         0  112108 train               4
    ##  4        1      49683                 4         0  112108 train               4
    ##  5        1      43633                 5         1  112108 train               4
    ##  6        1      13176                 6         0  112108 train               4
    ##  7        1      47209                 7         0  112108 train               4
    ##  8        1      22035                 8         1  112108 train               4
    ##  9       36      39612                 1         0   79431 train              23
    ## 10       36      19660                 2         1   79431 train              23
    ## # ℹ 1,384,607 more rows
    ## # ℹ 8 more variables: order_dow <int>, order_hour_of_day <int>,
    ## #   days_since_prior_order <int>, product_name <chr>, aisle_id <int>,
    ## #   department_id <int>, aisle <chr>, department <chr>

The dataset contains 138461 observations and 15 variables. Each
observation is a single product from an Instacart order. Key variables
include order_id: a different ID for each order; product_id: a different
ID for each product and product_name which is the name of the product.
The example product  
Bulgarian Yogurt has unique product id 49302 belong to yogurt aisel is
in order id 1 and has reordered once.

``` r
instacart|>
  count(aisle, sort = TRUE)
```

    ## # A tibble: 134 × 2
    ##    aisle                              n
    ##    <chr>                          <int>
    ##  1 fresh vegetables              150609
    ##  2 fresh fruits                  150473
    ##  3 packaged vegetables fruits     78493
    ##  4 yogurt                         55240
    ##  5 packaged cheese                41699
    ##  6 water seltzer sparkling water  36617
    ##  7 milk                           32644
    ##  8 chips pretzels                 31269
    ##  9 soy lactosefree                26240
    ## 10 bread                          23635
    ## # ℹ 124 more rows

There are 134 aisle in total and the most items ordered from fresh
vergetables.

``` r
instacart |>
  count(aisle, sort = TRUE) |>
  filter(n > 10000) |>
  mutate(aisle = fct_reorder(aisle, n)) |>
  ggplot(aes(x = n, y = aisle)) +
  geom_col(fill = "skyblue") +
  labs(
    title = "Number of Items Ordered by Aisle (>10,000 orders)",
    x = "Number of Items Ordered",
    y = "Aisle"
  )
```

<img src="p8105_hw3_yz5290_files/figure-gfm/unnamed-chunk-5-1.png" width="90%" />

``` r
top3tble=
  instacart |>
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) |>
  count(aisle, product_name, name = "num_orders") |>
  group_by(aisle) |>
  slice_max(order_by = num_orders, n = 3) |>
  ungroup()
top3tble
```

    ## # A tibble: 9 × 3
    ##   aisle                      product_name                             num_orders
    ##   <chr>                      <chr>                                         <int>
    ## 1 baking ingredients         Light Brown Sugar                               499
    ## 2 baking ingredients         Pure Baking Soda                                387
    ## 3 baking ingredients         Cane Sugar                                      336
    ## 4 dog food care              Snack Sticks Chicken & Rice Recipe Dog …         30
    ## 5 dog food care              Organix Chicken & Brown Rice Recipe              28
    ## 6 dog food care              Small Dog Biscuits                               26
    ## 7 packaged vegetables fruits Organic Baby Spinach                           9784
    ## 8 packaged vegetables fruits Organic Raspberries                            5546
    ## 9 packaged vegetables fruits Organic Blueberries                            4966

``` r
mean_hour_table=
  instacart |>
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) |>
  group_by(product_name, order_dow) |>
  summarize(mean_hour = mean(order_hour_of_day), .groups = "drop") |>
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour,
    names_prefix = "Day"
  )
mean_hour_table
```

    ## # A tibble: 2 × 8
    ##   product_name      Day0  Day1  Day2  Day3  Day4  Day5  Day6
    ##   <chr>            <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>
    ## 1 Coffee Ice Cream  13.8  14.3  15.4  15.3  15.2  12.3  13.8
    ## 2 Pink Lady Apples  13.4  11.4  11.7  14.2  11.6  12.8  11.9

``` r
mean_hour_table |>
  rename(
    Sunday=Day0,
    Monday=Day1,
    Tuesday=Day2,
    Wednesday=Day3,
    Thursday=Day4,
    Friday=Day5,
    Saturday=Day6
  )
```

    ## # A tibble: 2 × 8
    ##   product_name     Sunday Monday Tuesday Wednesday Thursday Friday Saturday
    ##   <chr>             <dbl>  <dbl>   <dbl>     <dbl>    <dbl>  <dbl>    <dbl>
    ## 1 Coffee Ice Cream   13.8   14.3    15.4      15.3     15.2   12.3     13.8
    ## 2 Pink Lady Apples   13.4   11.4    11.7      14.2     11.6   12.8     11.9

problem2

``` r
zipcode=read_csv("data/zipcode.csv")|>
  janitor::clean_names()
```

    ## Rows: 322 Columns: 7
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (4): County, County Code, File Date, Neighborhood
    ## dbl (3): State FIPS, County FIPS, ZipCode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
zori=read_csv("data/zori.csv")|>
  janitor::clean_names()
```

    ## Rows: 149 Columns: 125
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr   (6): RegionType, StateName, State, City, Metro, CountyName
    ## dbl (119): RegionID, SizeRank, RegionName, 2015-01-31, 2015-02-28, 2015-03-3...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
#clean data
zipcode_new=
  zipcode|>
  select(zip_code, county, neighborhood) |>
  distinct(zip_code, .keep_all = TRUE) |>
  mutate(zip_code = as.character(zip_code))

zori_new = 
  zori |>
  select(region_id, size_rank, region_name, region_type, 
         state_name, state, city, metro, county_name,
         x2015_01_31:x2024_08_31) |>
  pivot_longer(
    cols = x2015_01_31:x2024_08_31,
    names_to = "date_str",
    values_to = "rent_price"
  ) |>
  mutate(
    date_str_clean = str_remove(date_str, "^x") |> str_replace_all("_", "-"),
    date = as.Date(date_str_clean, format = "%Y-%m-%d"),
    zip_code = as.character(region_name)
  ) |>
  select(-date_str, -date_str_clean, -region_name)
```

``` r
final_data <- zori_new |>
  left_join(zipcode_new, by = "zip_code") |>
  select(zip_code, county, neighborhood, date, rent_price, everything()) |>
  arrange(zip_code, date)
```

\##count month

``` r
zip_obs_count=
  final_data |>
  group_by(zip_code) |>
  summarise(
    n_146 = n(),
    n_0 = sum(!is.na(rent_price))
  )

n_146_obs <- sum(zip_obs_count$n_146 == 116)
n_0_obs <- sum(zip_obs_count$n_0 < 10)
```

There are 149 zipcodes are observed 116 month and there are 26 zip code
observed fewer than 10 months. Some zipcodes reported monthly can have
data for 116 months. Some zipcode do not contain residential house like
unique university zipcode might not have rent price to report.

\##make a table (average rental price in each borough and year)

``` r
borough_t=
  final_data |>
  mutate(year = year(date)) |>
  filter(!is.na(county), !is.na(rent_price)) |>
  group_by(county, year) |>
  summarise(
    avg_rent = mean(rent_price, na.rm = TRUE),
    n_zips = n_distinct(zip_code),
    .groups = "drop"
  ) |>
  arrange(county, year)
reader_table=
  borough_t|>
  select(county, year, avg_rent) |>
  pivot_wider(
    names_from = year,
    values_from = avg_rent
  ) |>
  mutate(across(where(is.numeric), ~round(., 2)))
reader_table
```

    ## # A tibble: 5 × 11
    ##   county   `2015` `2016` `2017` `2018` `2019` `2020` `2021` `2022` `2023` `2024`
    ##   <chr>     <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>
    ## 1 Bronx     1760.  1520.  1544.  1639.  1706.  1811.  1858.  2054.  2285.  2497.
    ## 2 Kings     2493.  2520.  2546.  2547.  2630.  2555.  2550.  2868.  3015.  3126.
    ## 3 New York  3022.  3039.  3134.  3184.  3310.  3107.  3137.  3778.  3933.  4078.
    ## 4 Queens    2215.  2272.  2263.  2292.  2388.  2316.  2211.  2406.  2562.  2694.
    ## 5 Richmond    NA     NA     NA     NA     NA   1978.  2045.  2147.  2333.  2536.

\##comments on the trend: the rental price for each country increase
over year. New York has the highest rental price every year and bronx
has the lowest every year.

\#plot showing NYC Rental Prices within ZIP codes for all available
years. Your plot should facilitate comparisons across boroughs

``` r
plot1=
  final_data |>
  filter(!is.na(county), !is.na(rent_price)) |>
  mutate(year_month = floor_date(date, "month")) |>
  group_by(county, year_month) |>
  summarise(
    median_rent = median(rent_price, na.rm = TRUE),
    .groups = "drop"
  ) |>
  ggplot(aes(x = year_month, y = median_rent, color = county)) +
  geom_point(size=0.8) +
  labs(
    title = "NYC Rental Prices by Borough (2015-2024)",
    x = "Date", 
    y = "Median Rent",
    color = "Borough"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")
plot1
```

<img src="p8105_hw3_yz5290_files/figure-gfm/unnamed-chunk-13-1.png" width="90%" />

\##comment: Overall, the rent price increased from 2015 to 2024. But in
New York contry, rent pricedecerase from 2020 fall to 2021, which appear
to be a huge drop. This is not seen in the previous table. Bronx and
Queens also has a little drop in the same timee period.

\#Compute the average rental price within each ZIP code over each month
in 2023

``` r
zip_2023_avg=
  final_data|>
  mutate(year = year(date))|>
  filter(year == 2023, !is.na(rent_price), !is.na(county)) |>
  group_by(zip_code, county)|>
  summarise(
    avg_rent = mean(rent_price, na.rm = TRUE),
    .groups="drop"
  )

plot2=
  ggplot(zip_2023_avg, aes(x = avg_rent, y = county, fill = county))+
  geom_boxplot(alpha = 0.6) +
  labs(
    title = "Distribution of ZIP-code-level Rental Prices by Borough (2023)",
    x="Average Rent",
    y="Borough"
  )+
  theme_minimal()+
  theme(legend.position = "none")

plot2
```

<img src="p8105_hw3_yz5290_files/figure-gfm/unnamed-chunk-14-1.png" width="90%" />
\#comment: New York county has the highest average rental price with the
largest range. Kings the the second highest average rental price.
Richmond has lowest range. THe bronx has lowest average rental pricebut
richmond’s average rntal price is slight more than Bronx’s.

\#combine two graph and export.

``` r
combined_plot=
  plot1 /plot2



ggsave("result/nyc.png", combined_plot, 
       width = 12, height = 10)
```
